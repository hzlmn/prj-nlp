{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import en_core_web_lg\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import spacy\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "### The idea\n",
    "The idea is to align sentences and make some features based on wordnet synsets relationship (synonym, hyponym, hypernym, meronym, holonym, ...). To make true alignment is somewhat a big task, which need it's own (not so trivial) classifier. So I want to simplify step of allignment to this procedure:\n",
    "  * for each pair of sentences\n",
    "      * match each word in evidence sentence with each word in hypothesis\n",
    "      * for each match $(e_i, h_j)$\n",
    "          * compute following features:\n",
    "              * if $e_i$ is synonym for $h_i$ return 1 else 0\n",
    "              * if $e_i$ in the hypernym closure from $h_j$ to root return 1 else 0\n",
    "              * if $h_j$ in the hypernym closure from $e_i$ to root return 1 else 0\n",
    "              * if $e_i$ in the holonym closure from $h_j$ to root return 1 else 0\n",
    "              * if $h_j$ in the meronym closure from $e_i$ to root return 1 else 0\n",
    "              * if $e_i$ in the entailment closure from $h_j$ to root return 1 else 0\n",
    "              * if $h_j$ in the entailment closure from $e_i$ to root return 1 else 0\n",
    "          * penalize each features by the distance between $i$ and $j$: $| j - i | + 1$\n",
    "      * sum all results to have one number for each sentence pair\n",
    "      \n",
    "Simply speaking, this algorithm takes assumption that if word in evidence and hypothesis is aligned  it is very unlikely that they will be very far from each other. It is definetely not true, but we'll see how it works.\n",
    "\n",
    "### Baseline\n",
    "For baseline I will use simply a Logistic Regression and classifier on tf-idf word features for two sentences concatenated.\n",
    "\n",
    "### Steps\n",
    "* Train classifier only on wordnet features\n",
    "* Train classifier only on word embeddings\n",
    "* Train classifier on both word embeddings and wordnet features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'dataset/snli_1.0/snli_1.0_train.jsonl'\n",
    "TEST_FILE = 'dataset/snli_1.0/snli_1.0_test.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(file):\n",
    "    rows = [json.loads(line) for line in open(file)]\n",
    "    df = pd.DataFrame({\n",
    "        'sentence1': [r['sentence1'] for r in rows],\n",
    "        'sentence2': [r['sentence2'] for r in rows],\n",
    "        'sentence1_parse': [r['sentence1_parse'] for r in rows],\n",
    "        'sentence2_parse': [r['sentence2_parse'] for r in rows],\n",
    "        'label': [r['gold_label'] for r in rows]\n",
    "    })\n",
    "    return df[df['label'] != '-'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = prepare(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = prepare(TEST_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>A person on a horse jumps over a broken down airplane.</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>A person on a horse jumps over a broken down airplane.</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entailment</td>\n",
       "      <td>A person on a horse jumps over a broken down airplane.</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>The kids are frowning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                               sentence1  \\\n",
       "0        neutral  A person on a horse jumps over a broken down airplane.   \n",
       "1  contradiction  A person on a horse jumps over a broken down airplane.   \n",
       "2     entailment  A person on a horse jumps over a broken down airplane.   \n",
       "3        neutral                   Children smiling and waving at camera   \n",
       "4     entailment                   Children smiling and waving at camera   \n",
       "5  contradiction                   Children smiling and waving at camera   \n",
       "\n",
       "                                           sentence2  \n",
       "0  A person is training his horse for a competition.  \n",
       "1      A person is at a diner, ordering an omelette.  \n",
       "2                  A person is outdoors, on a horse.  \n",
       "3                  They are smiling at their parents  \n",
       "4                         There are children present  \n",
       "5                              The kids are frowning  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bc5aaf60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.label.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good that data is uniformly distributed across all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nb_pipe = make_pipeline(TfidfVectorizer(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_prepare(df):\n",
    "    return df.assign(concat=[t1 + \" \" + t2 for t1,t2 in zip(df['sentence1'], df['sentence2'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_data = nb_prepare(train)\n",
    "nb_test = nb_prepare(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_i...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipe.fit(nb_data['concat'], nb_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.591103943265613"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipe.score(nb_data['concat'], nb_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.57      0.56      0.57      3237\n",
      "   entailment       0.58      0.61      0.59      3368\n",
      "      neutral       0.57      0.55      0.56      3219\n",
      "\n",
      "  avg / total       0.57      0.57      0.57      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nb_test['label'], nb_pipe.predict(nb_test['concat'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple idea like concatenating sentences and train logistic regression on it give pretty good results: f1=**57%**. So I will try to beat this results, but it may be not so easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy2wn(spacy_pos):\n",
    "    if spacy_pos == 'NOUN':\n",
    "        return 'n'\n",
    "    elif spacy_pos == 'VERB':\n",
    "        return 'v'\n",
    "    else:\n",
    "        return 'NONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe009bb4360546b4b3ab9382831a9f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "from tqdm import tqdm_pandas\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f535c62f83e047139c6e437fdf436336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=549367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e548e663db641fe800f91f129e99e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=549367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train2 = train.assign(sentence1_doc=train['sentence1'].progress_apply(nlp))\n",
    "train2 = train2.assign(sentence2_doc=train['sentence2'].progress_apply(nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a4adca9d5848a5803dd3a3ca815d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9824), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56697803b8a54160982bad8f17a8f94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9824), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test2 = test.assign(sentence1_doc=test['sentence1'].progress_apply(nlp))\n",
    "test2 = test2.assign(sentence2_doc=test['sentence2'].progress_apply(nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cache = {}\n",
    "\n",
    "def synset(id):\n",
    "    res = None #cache.get(id)\n",
    "    if res == None:\n",
    "        res = wn.synset(id)\n",
    "        cache[id] = res\n",
    "    return res\n",
    "\n",
    "def extract_features(df):\n",
    "    features_list = []\n",
    "    for i,row in tqdm_notebook(df.iterrows(), total=len(df)):\n",
    "        sent1 = list(filter(lambda x: x.pos_ in {'NOUN', 'VERB'}, row['sentence1_doc']))\n",
    "        sent2 = list(filter(lambda x: x.pos_ in {'NOUN', 'VERB'}, row['sentence2_doc']))\n",
    "\n",
    "        sent1_uniq = set()\n",
    "        sent2_uniq = set()\n",
    "        features = {\n",
    "            'synonym': 0,\n",
    "            'hypernym': 0,\n",
    "            'hyponym': 0,\n",
    "            'holonym': 0,\n",
    "            'meronym': 0,\n",
    "            's1-ent->s2': 0,\n",
    "            's2-ent->s1': 0\n",
    "        }\n",
    "        for i in range(len(sent1)):\n",
    "            for j in range(len(sent2)):\n",
    "                dist = abs(i-j)+1\n",
    "                t1 = sent1[i]\n",
    "                t2 = sent2[j]\n",
    "                if t1.pos == t2.pos:\n",
    "                    try:\n",
    "                        s1 = synset(t1.lemma_ + '.' + spacy2wn(t1.pos_) + '.01')\n",
    "                        s2 = synset(t2.lemma_ + '.' + spacy2wn(t2.pos_) + '.01')\n",
    "                    except:\n",
    "                        continue\n",
    "                    features['synonym'] += (1 if t2.lemma_ in s1.lemma_names() else 0) / dist\n",
    "                    features['hypernym'] += (1 if any([s1 in hypernyms for hypernyms in s2.hypernym_paths()]) else 0) / dist\n",
    "                    features['hyponym'] += (1 if any([s2 in hypernyms for hypernyms in s1.hypernym_paths()]) else 0) / dist\n",
    "                    features['holonym'] += (1 if s1 in list(s2.closure(lambda x: x.member_holonyms() + x.part_holonyms() + x.substance_holonyms())) else 0) / dist\n",
    "                    features['meronym'] += (1 if s2 in list(s1.closure(lambda x: x.member_holonyms() + x.part_holonyms() + x.substance_holonyms())) else 0) / dist\n",
    "                    features['s1-ent->s2'] += (1 if s1 in list(s2.closure(lambda x: x.entailments())) else 0) / dist\n",
    "                    features['s2-ent->s1'] += (1 if s2 in list(s1.closure(lambda x: x.entailments())) else 0) / dist\n",
    "        features_list.append(features)\n",
    "        \n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104e399cc2cb45b28662c6b092c535da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=549367), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_list = extract_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bd50ca2d99409abaab00dbd97fe574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9824), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to train Logistic regression on this featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.4061984065296969\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.41      0.62      0.49      3237\n",
      "   entailment       0.44      0.47      0.45      3368\n",
      "      neutral       0.33      0.13      0.19      3219\n",
      "\n",
      "  avg / total       0.39      0.41      0.38      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "pipe1 = make_pipeline(DictVectorizer(), LogisticRegression())\n",
    "pipe1.fit(features_list, train2['label'])\n",
    "train_score1 = pipe1.score(features_list, train2['label'])\n",
    "print('train_score:', train_score1)\n",
    "test_pred1 = pipe1.predict(test_features)\n",
    "print(classification_report(test2['label'], test_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to train random forest on this features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.4581727697513684\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.46      0.51      0.48      3237\n",
      "   entailment       0.44      0.62      0.52      3368\n",
      "      neutral       0.39      0.17      0.24      3219\n",
      "\n",
      "  avg / total       0.43      0.44      0.41      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipe2 = make_pipeline(DictVectorizer(), RandomForestClassifier())\n",
    "pipe2.fit(features_list, train2['label'])\n",
    "train_score2 = pipe2.score(features_list, train2['label'])\n",
    "print('train_score:', train_score2)\n",
    "test_pred2 = pipe2.predict(test_features)\n",
    "print(classification_report(test2['label'], test_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest gave the best results for this features set. But we are much belowe the baseline still."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe classifier\n",
    "Let's try to use glove vectors for evidence and hypothesis to train classifier. For each sentence we will sum up all word vectors and than concatenate two resulting vectors into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022fbfb996d64a7cb0fa29276cd97326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glove_file = open('dataset/glove.6B/glove.6B.100d.txt')\n",
    "embedding_index = {}\n",
    "for line in tqdm_notebook(glove_file, total=400000):\n",
    "    parts = line.split()\n",
    "    word = parts[0]\n",
    "    vector = np.asarray([float(p) for p in parts[1:]])\n",
    "    embedding_index[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.base\n",
    "\n",
    "class SentenceEmbeddingExtractor(sklearn.base.TransformerMixin):\n",
    "    def __init__(self, embedding_index):\n",
    "        self.embedding_index = embedding_index\n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        self.unk = np.zeros((embedding_index['the'].shape[0],))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, sentences):\n",
    "        return np.asarray([\n",
    "            np.sum(np.asarray([self.embedding_index.get(token.lemma_, self.unk)  for token in sentence]), axis=0)\n",
    "            for sentence in sentences\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(sklearn.base.TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return df[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.5502405495779689\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.55      0.53      0.54      3237\n",
      "   entailment       0.56      0.61      0.58      3368\n",
      "      neutral       0.57      0.52      0.54      3219\n",
      "\n",
      "  avg / total       0.56      0.56      0.56      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe3 = make_pipeline(\n",
    "    FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('embeddings1', make_pipeline(ItemSelector('sentence1_doc'), \n",
    "                                          SentenceEmbeddingExtractor(embedding_index))),\n",
    "            \n",
    "            ('embeddings2', make_pipeline(ItemSelector('sentence2_doc'), \n",
    "                                          SentenceEmbeddingExtractor(embedding_index))),\n",
    "        ]\n",
    "    ),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "pipe3.fit(train2, train2['label'])\n",
    "train_score3 = pipe3.score(train2, train2['label'])\n",
    "print('train_score:', train_score3)\n",
    "test_pred3 = pipe3.predict(test2)\n",
    "print(classification_report(test2['label'], test_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **f1 = 56%** are pretty close to the baseline results (57%) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet and GloVe classifier\n",
    "Here we will try to concatenate wordnet features vector to the embeddings vector and train logistic regression on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = train2.assign(wn_features=features_list)\n",
    "test3 = test2.assign(wn_features=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.578489425101981\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.58      0.58      0.58      3237\n",
      "   entailment       0.60      0.66      0.63      3368\n",
      "      neutral       0.58      0.51      0.54      3219\n",
      "\n",
      "  avg / total       0.59      0.59      0.59      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe4 = make_pipeline(\n",
    "    FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('embeddings1', make_pipeline(ItemSelector('sentence1_doc'), \n",
    "                                          SentenceEmbeddingExtractor(embedding_index))),\n",
    "            \n",
    "            ('embeddings2', make_pipeline(ItemSelector('sentence2_doc'), \n",
    "                                          SentenceEmbeddingExtractor(embedding_index))),\n",
    "            \n",
    "            ('wn_features', make_pipeline(ItemSelector('wn_features'),\n",
    "                                          DictVectorizer()))\n",
    "        ]\n",
    "    ),\n",
    "    LogisticRegression()\n",
    ")\n",
    "pipe4.fit(train3, train3['label'])\n",
    "train_score4 = pipe4.score(train3, train3['label'])\n",
    "print('train_score:', train_score4)\n",
    "test_pred4 = pipe4.predict(test3)\n",
    "print(classification_report(test3['label'], test_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, we've beaten the baseline results by 3%. Not so much, but definetely a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Word embedding with wordnet features gives us good results for this task, but there are some of thigs to try:\n",
    "* Try longer word vector (> 100)\n",
    "* Try to use more smooth function for penalizing wordnet features. `(1, 1/2, 1/3, 1/4, 1/5, ..)` is not so smooth at the beggining.\n",
    "* Try to normalize result number for sentence from wordnet features by the length of sentence.\n",
    "* (as always) try different classifier (NN or other non-linear)\n",
    "* (as always) do hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
