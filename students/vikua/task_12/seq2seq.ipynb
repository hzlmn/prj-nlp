{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tokenize_uk\n",
    "from gensim.models import Phrases\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Kobzar.txt', 'r') as f: \n",
    "    data = f.read()\n",
    "    sentences = sent_tokenize(data, language='russian')\n",
    "    sentence_stream = [tokenize_uk.tokenize_words(x.lower()) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sentence_stream, min_count=1)\n",
    "bigram = Phrases(phrases[sentence_stream], min_count=1, delimiter=b' ')\n",
    "trigram = Phrases(bigram[sentence_stream], min_count=1, delimiter=b' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['кобзар',\n",
       " 'шевченко',\n",
       " 'тарас',\n",
       " 'тарас шевченко',\n",
       " '/',\n",
       " '“',\n",
       " 'кобзар',\n",
       " '”',\n",
       " 'шевченко',\n",
       " 'народився',\n",
       " 'у',\n",
       " 'селі',\n",
       " 'моринці',\n",
       " 'київської',\n",
       " 'губ',\n",
       " '.',\n",
       " ',',\n",
       " 'в',\n",
       " 'родині',\n",
       " 'селянина',\n",
       " '- кріпака',\n",
       " '.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram[sentence_stream[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(list(trigram.vocab.items()), key=lambda x: x[1], reverse=True)\n",
    "counts = [(x[0].decode(\"utf-8\"), x[1]) for x in a]\n",
    "\n",
    "overall_count = sum([x[1] for x in counts])\n",
    "probabilities = {x[0]: x[1] / float(overall_count) for x in counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031724137931034485"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[', що'] / probabilities[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "як діток старими сльозами ледве вийшла ти , треба було ?.. а я таки набрались , доглядають . - за що й\n",
      "як той не прошу . — про історичну долю добуде , як була я остануся тута , де б воеводу татары убили или\n",
      "як тая слава ... мати — адамові діти ! » ) , неначе злодій , де вінчати , неначе в лози колисочку\n",
      "як рівний з дітками . - ха - де він мене в египетской темнице . - петербург ] послание первое святаго\n",
      "як той поговір , косарал ] * * * * * * * у черниці постриглась . - сердеги . -\n",
      "як я усну , гріхи . - пустиня , не пом'яне ! » ) . - запорожці , а всі упали до\n",
      "як рукою махає . согласьем общим положили ті сироти . і дні минають дні і я ледве ступаю ; весело жилось ,\n",
      "як квіточку , уже забува ? ” , росте марко з найпопулярніших творів періоду творчості і сіль і людям однаково ,\n",
      "як на сміх людям однаково , обнімала , і стиха , то й читать ! » і їх , а щоб і пріся\n",
      "як нас в люди хреститимуть , ні , серцем до вас не спіткали » ( співає : хто світ . - вихваляєш :\n"
     ]
    }
   ],
   "source": [
    "start = 'як'\n",
    "\n",
    "def generate(start, count):\n",
    "    result = []\n",
    "    result.append(start)\n",
    "    for i in range(count):        \n",
    "        keys = [k for k in probabilities.keys() if k.startswith('{} '.format(start))]\n",
    "        weights = np.array([probabilities[k] for k in keys])\n",
    "\n",
    "        scale_factor = 1 / sum(weights) \n",
    "        weights *= scale_factor\n",
    "\n",
    "        nxt = np.random.choice(keys, p=weights)\n",
    "        result.append(' '.join(nxt.split(' ')[1:]))\n",
    "        start = nxt.split(' ')[-1]\n",
    "    return result \n",
    "\n",
    "for i in range(10): \n",
    "    print(' '.join(generate(start, 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespear.txt', 'r') as f: \n",
    "    lines = f.readlines()\n",
    "    lines = lines[89:]\n",
    "    chars = [list(l) for l in lines]\n",
    "    chars = [l for l in chars if len(l) <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [item for sublist in chars for item in sublist]\n",
    "n_chars = len(data)\n",
    "vocab = sorted(list(set(data)))\n",
    "char_to_idx = {c: i for i, c in enumerate(vocab)}\n",
    "idx_to_char = {i: c for c,i in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [item for sublist in chars for item in sublist]\n",
    "n_chars = len(data)\n",
    "vocab = sorted(list(set(data)))\n",
    "char_to_idx = {c: i for i, c in enumerate(vocab)}\n",
    "\n",
    "sequence_length = 100 \n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in range(n_chars - sequence_length - 1):\n",
    "    seq_in = data[i:i + sequence_length]\n",
    "    seq_out = data[i + 1:i + sequence_length + 1]\n",
    "    data_x.append([char_to_idx[e] for e in seq_in])\n",
    "    data_y.append([char_to_idx[e] for e in seq_out])\n",
    "\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x12b598eb8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x12b930908>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "INFO:tensorflow:Restoring parameters from kobzar_bin/model_final.ckpt\n",
      "-----------------------Start------------------------\n",
      " a knnesdd?\n",
      "In herself'comsmths aun\n",
      "\n",
      "Bur thrap waundrissle  in eipel alpiever\n",
      "An with op ecfitce of so\n",
      "oor soild behelf the fuee\n",
      "Bf weuct ou beeatton, wer sirs will hror Calcentan'o the peint place cooder me.\n",
      "Hisphechirg' oy us af enemy\n",
      "eeaen'd\n",
      "so seally yoy, go tullean by hor,\n",
      "On a patracas; ald tiy reabon dosblece mo.\n",
      "hewssall as bir.\n",
      "The which not begl'd hands of lasters ie the sien!\n",
      "And staul to, th butsot'd could yourwhem\n",
      "Rive sare you tpeak.\n",
      "\n",
      "MIRK:\n",
      "A hinid your grece whose e'e deppatiou! till mome:\n",
      "Me trie d eith obroantol'd peers ard anl the rank\n",
      "That mekbiest ir dispheature and mieh indains mocomeriot ulon\n",
      "Sime, and to be, her faole, our ord.\n",
      "I in the measteriof the soft\n",
      "Will ware I lonjer in the revalty, and tlim spon\n",
      "Af eny ag an\n",
      "If vlece ore you will.\n",
      "\n",
      "FUSSTUS:\n",
      "I tovon leave yos offeratn; and theyshave hem.\n",
      "LAt shokews sh armesoot father's lity: the mast\n",
      "That tels hess nell and blombonoyour antanply tascurs;\n",
      "The hirmf fer in the aplabtent coufes with thee,\n",
      "And blink nit e lay asous\n",
      "abdy be sistenntoof my friend\n",
      "\n",
      "eld know nom facen ond th corit!!\n",
      "But lnt on the somerfirlains, indet st; ane which on sis\n",
      "BGud ham to home us ie: your rieamnss folrow,\n",
      "She saard ehem, I woe one pies at'd I shall potshike now,is from the woeld, Whics weenst beacy toford me herd, I choek to wardan so guildy and\n",
      "two ciristsenf her aapihar ple:\n",
      "There'd he bur ievar line the luveran pallon Iball tamservent 't another Well verouss\n",
      "They, if a bosemess, alds in fight, thry though hissorved us en himdelf, the llewe than thy wors\n",
      "Be wat in macded poets\n",
      "so wemr my fook with se mtemew mady tite\n",
      "To teavea wille:\n",
      "\n",
      "NORIOLK:\n",
      "Ster's th to: and e would\n",
      "you phoce deserd andecon,\n",
      "Which drysiccrision, for nhoir theid,Then cim the simbectition of the vomenbo coud insmane:\n",
      "The perrent foryedikning them fand.\n",
      "\n",
      "LLEENA::As it would bave a ladsy sioss of a biodle, procles\n",
      "And it she ribleculfod hieseof blcomp.\n",
      "\n",
      "ROSALIND:\n",
      "E wighfrn', ter mo weat them Ias my dursitt\n",
      "\n",
      "YARK ANTONY:\n",
      "Well, hou grod mird,\n",
      "BROST"
     ]
    }
   ],
   "source": [
    "from model import GenModel\n",
    "import sys\n",
    "\n",
    "\n",
    "params = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'sequence_length': sequence_length,\n",
    "    'dropout_keep_prob': 1,\n",
    "    'hidden_units': 256,\n",
    "    'num_layers': 2,\n",
    "}\n",
    "\n",
    "with tf.Graph().as_default():     \n",
    "    model = GenModel(params)\n",
    "    model.build_graph()\n",
    "    \n",
    "    session = tf.Session()\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    saver.restore(session, 'kobzar_bin/model_final.ckpt')\n",
    "    \n",
    "    state = np.zeros((1, 2 * 2 * 256)) \n",
    "    \n",
    "    print('-----------------------Start------------------------')\n",
    "    start = 'The'\n",
    "    start_x = [char_to_idx[x] for x in start]\n",
    "    for e in start_x: \n",
    "        pred, new_state = session.run([model.predictions, model.last_state], feed_dict={\n",
    "            model.input_x: np.array([e]).reshape(1, 1),\n",
    "            model.dropout_keep_prob: 1,\n",
    "            model.lstm_state: state\n",
    "        })\n",
    "        probabilities = pred[0][0]        \n",
    "        state = new_state\n",
    "\n",
    "    for _ in range(2000): \n",
    "        element = np.random.choice(range(vocab_size), p=probabilities)\n",
    "        sys.stdout.write(idx_to_char[element])\n",
    "        pred, new_state = session.run([model.predictions, model.last_state], feed_dict={\n",
    "            model.input_x: np.array([element]).reshape(1, 1),\n",
    "            model.dropout_keep_prob: 1,\n",
    "            model.lstm_state: state\n",
    "        })\n",
    "        probabilities = pred[0][0]        \n",
    "        state = new_state  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
