    Побудова бейзлайну курсового проекту

Тема: дослідження суб‘єктивності в текстах новин українською мовою.

Задача мінімум - пошук суб‘єктивних виразів та речень в текстах новин та оцінка об‘єктивності всієї новини.
Задача максимум - пошук анентів які вживають суб‘єктивну лексику та агентів проти яких вона вживається,
екстакшен інформації про те хто про кого кому і як суб‘єкутивно висловлювався.

Проект знаходиться в репозиторії https://github.com/vikua/nlp-subjectivity
Зроблено наступне
- Зібрано дуже багато сирих даних із різних сайтів новин.
    - код спайдерів [тут](https://github.com/vikua/nlp-subjectivity/tree/master/python/scrappers)
    - дані на S3 в бакеті `vikua-news-data`
- Дані розмічено в semi-supervised режимі. Начитавшись різних пейперів по сентімєнт аналізу та sentiwordnet
https://www.researchgate.net/profile/Kerstin_Denecke/publication/4330825_Using_SentiWordNet_for_multilingual_sentiment_analysis/links/00463526769e2e3c11000000.pdf
https://arxiv.org/pdf/1309.5843.pdf
http://stp.lingfil.uu.se/~santinim/sais/Ass1_Essays/Neele_Julia_SentiWordNet_V01
А також інших, лінки на як я не зберіг, я вирішив перекласти всі новини на англійску за допомогою Google Translate API
i порахувати середню об‘єктивнінсть за допомогою sentiworknet.
Викристання тонального словнику української мови я теж намагався спробувати, але результат перекладу вийшов кращим.
Код перекладача [тут](https://github.com/vikua/nlp-subjectivity/blob/master/python/translation.py).
Кожне речення перекладене окремо, для того щоб збегігся мапінг речення en <-> речення uk. Якщо перекладати
новину повністю як єдиний текст гугл щось мудрує та робить з кількох речень одне і навпаки (що впринципі добре, але не для моєї задачі).
- Далі я мануально переглянув більшість (скільки зміг) речень та виправив деякі помилки в лейблах. 
Одна із проблем наприклад була в тому що sentiwordnet найбільш позитивними чи негативними ввадає речення із багатим набором 
прикметників, а наприклад фрази "я вважаю", "я думаю" і тд часто помічає як об‘єктивні (принаймні мій алгоритм так робить).
Деякий код із таким аналізом [тут](https://github.com/vikua/nlp-subjectivity/blob/master/python/exploration.ipynb)
- Я взяв невеликий семпл (~15k новин, в реченнях ~200к), розмітив та взяв тільки ті про які мій алгоритм був супер 
впевнений що вони або суб‘єктивні або об‘єктивні, потім мануально перевірив та виправив. 
Вийшло ~90к об‘єктивних речень та ~12к суб‘єктивних (що схоже на правду, тому що я взяв короткі новини, які здебільшого
містять якісь факти, та трохи меньше політичних блогів). Всеж впевнений звичайно, що десь там щось розмичено не зовсім якісно ;(
- Бейзлайн на класифікацію https://github.com/vikua/nlp-subjectivity/blob/master/python/baseline_model.ipynb побудований на 
lemmatication -> stop words removal -> bag-of-words -> sgd classifier.
Метрика f1_score вийшла вище ніз я очікував - 0.82

Наступні кроки - покращита бейзлайн класифікації та перейти до coreference detection та information retrieval про те 
які агенти що про кого/що там кажуть.