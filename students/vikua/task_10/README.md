### Задача 10

Я взял по 20 тыс для каждого класса entailment, contradiction, neutral, так как весь датасет обработать на локальной машине 
за вменяемое время чтобы можно быть итерировать не получилось.

Из фич WordNet я использовал разные similarity метрики, которые учитывают разные связи между рутами и самими словами. 
Как следующий шаг улучшения, я попробовал разные векторные представления - TF-IDF, претренированные word2vec GoogleNews,
натренированные word2vec устредненные и взвешенные TF-IDF, устедненные fasttext.

Задача решалась с помощью классификации с метрикой f1

Результат: 
- WordNet simlarity metrics: SGD - 0.39, LGBM - 0.42
- TF-IDF: SGD - 0.57, LGBM - 0.67
- Pretrained GoogleNews Word2vec (mean): SGD: 0.58, LGBM - 0.65
- Pretrained GoogleNews Word2vec (tfidf weighted): SGD: 0.53, LGBM - 0.64
- Trained Word2vec (mean): 0.53, LGBM: 0.63
- Trained Fasttext (mean): 0.51, LGMB: 0.61

В результате лучшее качество у TF-IDF и претренированых word2vec. 
Как дальшейшее улучшение имеет смысл натренировать векторы на полном тренировочном датасете, в котором всего 500к записей (я использовал 60к рандомных). 
Удаление stopwords а так же использование только лемматизированных слов (без pos тегов) улучшений не дало.